{
  "cells": [
    {
      "metadata": {
        "_uuid": "cc070c244403405160c4023979ce35e28f32bc4e",
        "_cell_guid": "93c82a19-bf92-4a75-a769-cee9dbbba7e7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport cv2                 # working with, mainly resizing, images\nimport numpy as np         # dealing with arrays\nimport os                  # dealing with directories\nfrom random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\nfrom tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BÃ¼hler for this suggestion\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\n%cd /kaggle/working\n\nTRAIN_DIR = '../input/dogs-vs-cats-redux-kernels-edition/train'\nTEST_DIR = '../input/dogs-vs-cats-redux-kernels-edition/test'\n\n#print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))\n\nIMG_SIZE = 50\nLR = 1e-3\n\n#MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8e50b666fb34222b8f71acdec84188a8092156f3",
        "_cell_guid": "d60c7add-f6f6-4b2c-8d0a-27415840b2b8",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def label_img(img):\n    word_label = img.split('.')[-3]\n    # conversion to one-hot array [cat,dog]\n    #                            [much cat, no dog]\n    if word_label == 'cat': return [1]\n    #                             [no cat, very doggo]\n    elif word_label == 'dog': return [0]\n    \ndef create_train_data():\n    training_data = []\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        label = label_img(img)\n        path = os.path.join(TRAIN_DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        \n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([img,label])\n    \n    #cv2.imshow(\"foo\", img)\n    shuffle(training_data)\n    \n    training_data = np.array(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data\n\ndef process_test_data():\n    testing_data = []\n    for img in tqdm(os.listdir(TEST_DIR)):\n        path = os.path.join(TEST_DIR,img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        testing_data.append([np.array(img), img_num])\n        \n    shuffle(testing_data)\n    np.save('test_data.npy', testing_data)\n    return testing_data\n\n\ntrain_data = create_train_data()\ntest_data = process_test_data()\n# If you have already created the dataset:\n#train_data = np.load('train_data.npy')\n#test_data = np.load('test_data.npy')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb5458a7e8ff27d36300471544899b56252477e3",
        "_cell_guid": "3d5012c7-19f8-432e-9567-a810a33af8f4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from matplotlib import pyplot as plt\n\nfrom PIL import Image\n#plt.imshow(train_data[0][0])\nImage.fromarray(train_data[2][0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ae60c5cbf9c8ad8825dae3e9c80a9e7b9c6448a7",
        "_cell_guid": "7ad8adac-fcaf-483a-a50e-f9d38d3a77d3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential, Model, load_model\nfrom keras.applications.vgg16 import VGG16\n\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense, Activation\n\nfrom keras.models import Sequential\nfrom keras import utils",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "695e7a9337aa581c3693f8ec256bfb31c9fef8e6",
        "_cell_guid": "dbe0f870-bb02-445a-93a8-0bbd053fac85",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Weights for VGG16\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\nimg_rows, img_cols, img_channel = IMG_SIZE, IMG_SIZE, 3\n\nWEIGHTS_DIR = '../input/vgg16'\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\nprint(check_output([\"ls\", WEIGHTS_DIR]).decode(\"utf8\"))\n!cp ../input/vgg16/*notop* ~/.keras/models/\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bcae10be1e9b5edf45ee0bba18f01c210956a933",
        "collapsed": true,
        "_cell_guid": "3ec60324-6c0c-48a6-85e4-5622990358bd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = train_data[:-500]\ntest = train_data[-500:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "90279ef517be5a6ca3664bcadc18c9b17498ad72",
        "collapsed": true,
        "_cell_guid": "ad76373c-4f2a-486b-a628-ecdeaf122b5e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nY = [i[1] for i in train]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0fe93af2dc1d753dd81c56918382ddbf0211c994",
        "collapsed": true,
        "_cell_guid": "2872278b-0fa3-45b3-ab66-1a63b29c1661",
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\ntest_y = np.array([i[1] for i in test])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a00acf1997d6d6ec3e36862ca7dfd1e9bad0bf56",
        "scrolled": true,
        "_cell_guid": "4860395d-4fce-4233-88f2-a79a9a7ed0a3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras import backend as K\n\n#model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n#model.add(Activation('relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Flatten())\n#model.add(Dense(64))  # we now have numbers not 'images'\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n    # Output Layer\nmodel.add(Dense(1))\n#model.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\nmodel.fit(X[:600], np.array(Y)[:600], epochs=1, batch_size=600, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6f99435d9623b8143a35d775d6ac6c98da41f5f5",
        "_cell_guid": "4b8cd14b-af8f-4ba8-ad9f-eeb9f154f2ab",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\nfrom keras.models import Sequential\n\n\ndef shallow_net():\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    # this converts our 3D feature maps to 1D feature vectors\n    model.add(Flatten())\n\n    model.add(Dense(64))  # we now have numbers not 'images'\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n\n    # Output Layer\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    \n    return model\n\nmodel = shallow_net()\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n#model.summary()\n\n\nmodel.fit(X, np.array(Y), epochs=1, batch_size=6000, verbose=1)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22128ee9f274ae3ec7db5dfdb21f2e40a31c93c4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\nimport random\n\nd = random.choice(test_data)\nimg_data, img_num = d\ndata = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\nprediction = model.predict(np.array([data]))[0]\n\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_subplot(111)\nax.imshow(img_data, cmap=\"gray\")\nprint(f\"{prediction[0]}% likelihood it is a cat\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "987f120ab19018f5f8c5a90c17b66c016560b217",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}