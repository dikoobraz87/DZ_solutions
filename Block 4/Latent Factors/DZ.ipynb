{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# создаём сессию Spark\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Загружаем предрасчитанную матрицу\n",
    "from scipy.sparse import load_npz\n",
    "user_item_matrix = load_npz(\"/data/other/user_item_lastfm.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# делим разреженную матрицу на обучающую и тестовую\n",
    "total_len = user_item_matrix.data.size\n",
    "train_len = int(total_len * 0.8)\n",
    "all_indices = np.arange(total_len) ## Создаем массив длинной непустых значений\n",
    "np.random.seed(42) \n",
    "train_indices = np.random.choice(all_indices, train_len, replace=False) ##случайно выбираем номера непустых значений для трейна\n",
    "train_mask = np.in1d(all_indices, train_indices)  ## получаем массив из длинной непустых значений и маркеруем его тру фолс, если он присутствует в трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def get_masked(arr, mask):\n",
    "    return coo_matrix(\n",
    "        (\n",
    "            [np.float32(item) for item in arr.data[mask]],\n",
    "            (arr.row[mask], arr.col[mask])\n",
    "        ),\n",
    "        arr.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Делим на train и test\n",
    "train_csr = get_masked(user_item_matrix, train_mask).tocsr()\n",
    "train = train_csr.T\n",
    "test_coo = get_masked(user_item_matrix, ~train_mask)\n",
    "test_csr = test_coo.tocsr()\n",
    "test = test_csr.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# пробуем несколько моделей из Implicit. В итоге не одна из них не дала точность больше 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Пробуем ALS\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import os\n",
    "\n",
    "# автор пакета утверждает, что так быстрее\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "# обучаемся на тех же параметрах, что и в Spark\n",
    "als = AlternatingLeastSquares(\n",
    "    factors=10,\n",
    "    iterations=10,\n",
    "    regularization=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours  import BM25Recommender\n",
    "\n",
    "bm25 = BM25Recommender(\n",
    "     K1 =  100\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "bpr= BayesianPersonalizedRanking(\n",
    "    learning_rate = 0.1,\n",
    "    regularization = 0.01,\n",
    "    factors =40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 s, sys: 10 ms, total: 3.08 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bpr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_filename = \"/data/other/implicit_top50.pkl\"\n",
    "users = set(test_coo.row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 270 ms, total: 1min 51s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_recs(users, model):\n",
    "    return {\n",
    "        user: model.recommend(userid=user, user_items=train_csr, N=50)\n",
    "        for user in users\n",
    "    }\n",
    "\n",
    "# посчитаем по 50 рекомендаций для каждого пользователя из тестовой выборки\n",
    "recs = get_recs(users, bpr)\n",
    "# сохраним предрасчёт рекомендаций\n",
    "with open(pickle_filename, \"wb\") as f:\n",
    "    pickle.dump(recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# загрузим сохранённый предрасчёт\n",
    "with open(pickle_filename, \"rb\") as f:\n",
    "    recs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|          prediction|\n",
      "+-------+--------------------+\n",
      "|  85266|[137312, 153191, ...|\n",
      "|  85267|[145362, 71187, 1...|\n",
      "|  85268|[159390, 31532, 8...|\n",
      "|  85269|[8603, 4612, 5991...|\n",
      "|  85270|[35301, 94672, 11...|\n",
      "|  85271|[154626, 20798, 4...|\n",
      "|  85272|[7092, 74405, 119...|\n",
      "|  85273|[57960, 56580, 74...|\n",
      "|  85274|[20530, 74296, 41...|\n",
      "|  85275|[128208, 80495, 2...|\n",
      "|  85276|[29680, 99476, 28...|\n",
      "|  85277|[78755, 57626, 11...|\n",
      "|  85278|[5875, 26983, 245...|\n",
      "|  85279|[75376, 154756, 1...|\n",
      "|  85280|[144597, 49054, 1...|\n",
      "|  85281|[132887, 109676, ...|\n",
      "|  85282|[134385, 61576, 6...|\n",
      "|  85283|[107658, 22858, 6...|\n",
      "|  85284|[65504, 147624, 1...|\n",
      "|  85285|[69745, 100622, 6...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## создаем Spark объект полученных рекомендаций для функции precision\n",
    "import pandas as pd\n",
    "\n",
    "## удаляем из массива score оставляя только items\n",
    "recs_mod1 = {}\n",
    "i = 1\n",
    "for user in recs:\n",
    "    items_list = []\n",
    "    for items in recs[user]:\n",
    "        items_list.append(items[0])\n",
    "    recs_mod1[user] = items_list\n",
    "    \n",
    "recs_df =  pd.DataFrame.from_dict(recs_mod1,orient='index') # создаем DF из словаря\n",
    "recs_df ['prediction'] =  recs_df.values.tolist() ### объеденямем все колонки в один список\n",
    "recs_df_list = recs_df['prediction'].reset_index().rename(index=str, columns={\"index\": \"user_id\"}) ## получаем нужный формат\n",
    "##recs_df_list.head()\n",
    "predictions = spark.createDataFrame(recs_df_list)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|user_id|  item|      data|\n",
      "+-------+------+----------+\n",
      "|  84406|    64|    4.5625|\n",
      "|  84406|  8025|5.41796875|\n",
      "|  84406| 30174| 5.0234375|\n",
      "|  84406| 31403|4.75390625|\n",
      "|  84406| 51209|4.31640625|\n",
      "|  84406| 57969|   4.21875|\n",
      "|  84406| 79365| 4.5234375|\n",
      "|  84406| 87370|   4.21875|\n",
      "|  84406| 89401|   4.34375|\n",
      "|  84406|109744|4.27734375|\n",
      "|  84406|112328|  4.734375|\n",
      "|  84406|116497|5.31640625|\n",
      "|  84406|126203| 4.8046875|\n",
      "|  84406|129610|5.18359375|\n",
      "|  84407| 42269|3.46484375|\n",
      "|  84407| 49575|3.63671875|\n",
      "|  84407| 50461|4.14453125|\n",
      "|  84407| 55744| 4.4765625|\n",
      "|  84408|  4759|3.43359375|\n",
      "|  84408|  9596|3.43359375|\n",
      "+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## создаем набор объект spark test для дальнейшего искользования в функции precision\n",
    "test_df =  pd.DataFrame({'user_id': test_coo.row, 'item': test_coo.col, 'data': test_coo.data}\n",
    "                 )[['user_id', 'item', 'data']].sort_values(['user_id', 'item']\n",
    "                 ).reset_index(drop=True)\n",
    "test_spark = spark.createDataFrame(test_df)\n",
    "test_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sql_func\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "# используем стандартную Spark функцию для оценки точности\n",
    "def get_precision(recs, k):\n",
    "    \n",
    "    \n",
    "    predictions_and_labels = (\n",
    "        test_spark\n",
    "        .groupBy(\"user_id\")\n",
    "        .agg(sql_func.collect_list(\"item\").alias(\"label\"))\n",
    "        .join(predictions, \"user_id\")\n",
    "        .select(\"prediction\", \"label\")\n",
    "        .rdd\n",
    "    )\n",
    "    return RankingMetrics(predictions_and_labels).precisionAt(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07537493952588298"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем точность. Это Максимум, что получилось, для модели BayesianPersonalizedRanking\n",
    "get_precision(predictions, 1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
